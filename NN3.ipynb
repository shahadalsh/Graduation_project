{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e52c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers as l\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "\n",
    "#import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3593e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"/Users/shahrasm/Documents/Graduation_project/\"\n",
    "modelpath=path+\"bestmodel\"\n",
    "col=range(71)\n",
    "\n",
    "train_data = pd.read_csv(path+'train_data.csv',names=col)#, delimiter=',')\n",
    "Xtr = train_data.loc[:,1:]\n",
    "ytr = train_data.loc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787dc0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 70)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f78f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path+'test_data.csv',names=col)\n",
    "Xts = test_data.loc[:,1:]\n",
    "yts = test_data.loc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67bfdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 01:34:57.903294: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tr=[]\n",
    "for c in range(1,71):\n",
    "    e=Xtr[c]\n",
    "    meanc=np.mean(e) \n",
    "    varc=np.var(e) \n",
    "    normalize=l.Normalization(mean=meanc,variance=varc)\n",
    "    e=normalize(e)\n",
    "    tr.append(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1dd5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts=[]\n",
    "for c in range(1,71):\n",
    "    e=Xts[c]\n",
    "    meanc=np.mean(e) \n",
    "    varc=np.var(e) \n",
    "    normalize=l.Normalization(mean=meanc,variance=varc)\n",
    "    e=normalize(e)\n",
    "    ts.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58bf2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr=np.array(tr)\n",
    "Xtr=np.transpose(Xtr)\n",
    "Xts=np.array(ts)\n",
    "Xts=np.transpose(Xts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63ddee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg12=tf.keras.regularizers.l2()\n",
    "init=tf.keras.initializers.RandomNormal(stddev=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d22964",
   "metadata": {},
   "outputs": [],
   "source": [
    "myins = []\n",
    "for c in range(1,71):\n",
    "    d=l.Input(shape=(1,), dtype=tf.float32) \n",
    "    myins.append(d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87366d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r0=l.Lambda(lambda x:l.concatenate(x))(myins)\n",
    "r=l.Reshape((1,70))(r0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf961e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_71 (InputLayer)          [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 70)        0           ['input_71[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 2048)      145408      ['reshape[1][0]',                \n",
      "                                                                  'reshape[1][0]',                \n",
      "                                                                  'reshape[1][0]']                \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 1, 2048)      0           ['dense[4][0]',                  \n",
      "                                                                  'dense[5][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1, 4096)      0           ['attention[1][0]',              \n",
      "                                                                  'dense[3][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1024)      4195328     ['concatenate[1][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 1024)      0           ['dense_1[1][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1, 512)       524800      ['dropout[1][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1, 512)       0           ['dense_2[1][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1, 256)       131328      ['dropout_1[1][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1, 256)       0           ['dense_3[1][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1, 128)       32896       ['dropout_2[1][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 1, 128)       0           ['dense_4[1][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1, 1)         129         ['dropout_3[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,029,889\n",
      "Trainable params: 5,029,889\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Project=l.Dense(2048, activation='linear',activity_regularizer=reg12,kernel_initializer=init)    # accuracy 72.29  73.49\n",
    "key=Project(r)\n",
    "val=Project(r)\n",
    "query=Project(r)\n",
    "vk=l.Attention()([key,val])\n",
    "vkq=l.Concatenate()([vk,query])\n",
    "fc=l.Dense(1024, activation='relu',activity_regularizer=reg12)(vkq)\n",
    "fc=l.Dropout(0.2)(fc)\n",
    "fc=l.Dense(512, activation='relu',activity_regularizer=reg12)(fc)\n",
    "fc=l.Dropout(0.2)(fc)\n",
    "fc=l.Dense(256, activation='relu',activity_regularizer=reg12)(fc)\n",
    "fc=l.Dropout(0.2)(fc)\n",
    "fc=l.Dense(128, activation='relu',activity_regularizer=reg12)(fc)\n",
    "fc=l.Dropout(0.2)(fc)\n",
    "pre=l.Dense(1, activation='sigmoid',activity_regularizer=reg12)(fc)\n",
    "model = k.Model(inputs=r0, outputs=pre)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "393b8d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahrasm/myenv/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.2336 - binary_accuracy: 0.4438 - val_loss: 1.1101 - val_binary_accuracy: 0.4359\n",
      "Epoch 2/250\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.2335 - binary_accuracy: 0.4179 - val_loss: 1.1082 - val_binary_accuracy: 0.4872\n",
      "Epoch 3/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2283 - binary_accuracy: 0.4640 - val_loss: 1.1063 - val_binary_accuracy: 0.4872\n",
      "Epoch 4/250\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.2238 - binary_accuracy: 0.4841 - val_loss: 1.1044 - val_binary_accuracy: 0.4872\n",
      "Epoch 5/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.2205 - binary_accuracy: 0.4986 - val_loss: 1.1026 - val_binary_accuracy: 0.4615\n",
      "Epoch 6/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.2198 - binary_accuracy: 0.4669 - val_loss: 1.1007 - val_binary_accuracy: 0.5128\n",
      "Epoch 7/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.2154 - binary_accuracy: 0.4726 - val_loss: 1.0990 - val_binary_accuracy: 0.4872\n",
      "Epoch 8/250\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.2094 - binary_accuracy: 0.5504 - val_loss: 1.0972 - val_binary_accuracy: 0.4872\n",
      "Epoch 9/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.2088 - binary_accuracy: 0.5245 - val_loss: 1.0954 - val_binary_accuracy: 0.5128\n",
      "Epoch 10/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.2060 - binary_accuracy: 0.5476 - val_loss: 1.0937 - val_binary_accuracy: 0.5128\n",
      "Epoch 11/250\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2031 - binary_accuracy: 0.5447 - val_loss: 1.0920 - val_binary_accuracy: 0.5128\n",
      "Epoch 12/250\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1994 - binary_accuracy: 0.5677 - val_loss: 1.0904 - val_binary_accuracy: 0.4872\n",
      "Epoch 13/250\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1957 - binary_accuracy: 0.5677 - val_loss: 1.0887 - val_binary_accuracy: 0.4872\n",
      "Epoch 14/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1919 - binary_accuracy: 0.6023 - val_loss: 1.0871 - val_binary_accuracy: 0.5128\n",
      "Epoch 15/250\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1939 - binary_accuracy: 0.5648 - val_loss: 1.0855 - val_binary_accuracy: 0.5128\n",
      "Epoch 16/250\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.1910 - binary_accuracy: 0.5937 - val_loss: 1.0839 - val_binary_accuracy: 0.5128\n",
      "Epoch 17/250\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.1870 - binary_accuracy: 0.5994 - val_loss: 1.0823 - val_binary_accuracy: 0.5128\n",
      "Epoch 18/250\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1853 - binary_accuracy: 0.5735 - val_loss: 1.0808 - val_binary_accuracy: 0.5641\n",
      "Epoch 19/250\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.1809 - binary_accuracy: 0.6254 - val_loss: 1.0792 - val_binary_accuracy: 0.5897\n",
      "Epoch 20/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1759 - binary_accuracy: 0.6715 - val_loss: 1.0777 - val_binary_accuracy: 0.5641\n",
      "Epoch 21/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1747 - binary_accuracy: 0.6254 - val_loss: 1.0762 - val_binary_accuracy: 0.5641\n",
      "Epoch 22/250\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1693 - binary_accuracy: 0.6974 - val_loss: 1.0747 - val_binary_accuracy: 0.6154\n",
      "Epoch 23/250\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.1701 - binary_accuracy: 0.6542 - val_loss: 1.0732 - val_binary_accuracy: 0.6154\n",
      "Epoch 24/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1660 - binary_accuracy: 0.6744 - val_loss: 1.0717 - val_binary_accuracy: 0.6154\n",
      "Epoch 25/250\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1643 - binary_accuracy: 0.6542 - val_loss: 1.0702 - val_binary_accuracy: 0.6154\n",
      "Epoch 26/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1626 - binary_accuracy: 0.6571 - val_loss: 1.0687 - val_binary_accuracy: 0.6154\n",
      "Epoch 27/250\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1596 - binary_accuracy: 0.7118 - val_loss: 1.0673 - val_binary_accuracy: 0.6154\n",
      "Epoch 28/250\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1588 - binary_accuracy: 0.6686 - val_loss: 1.0658 - val_binary_accuracy: 0.6154\n",
      "Epoch 29/250\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.1568 - binary_accuracy: 0.6830 - val_loss: 1.0644 - val_binary_accuracy: 0.6154\n",
      "Epoch 30/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1508 - binary_accuracy: 0.7147 - val_loss: 1.0630 - val_binary_accuracy: 0.6154\n",
      "Epoch 31/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1512 - binary_accuracy: 0.7061 - val_loss: 1.0616 - val_binary_accuracy: 0.6154\n",
      "Epoch 32/250\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1472 - binary_accuracy: 0.7406 - val_loss: 1.0603 - val_binary_accuracy: 0.6154\n",
      "Epoch 33/250\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1463 - binary_accuracy: 0.7291 - val_loss: 1.0589 - val_binary_accuracy: 0.6154\n",
      "Epoch 34/250\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1430 - binary_accuracy: 0.7176 - val_loss: 1.0576 - val_binary_accuracy: 0.6154\n",
      "Epoch 35/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1411 - binary_accuracy: 0.7522 - val_loss: 1.0562 - val_binary_accuracy: 0.6410\n",
      "Epoch 36/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1401 - binary_accuracy: 0.6974 - val_loss: 1.0549 - val_binary_accuracy: 0.6410\n",
      "Epoch 37/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.1375 - binary_accuracy: 0.7435 - val_loss: 1.0536 - val_binary_accuracy: 0.6410\n",
      "Epoch 38/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.1348 - binary_accuracy: 0.7262 - val_loss: 1.0523 - val_binary_accuracy: 0.6410\n",
      "Epoch 39/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.1325 - binary_accuracy: 0.7320 - val_loss: 1.0510 - val_binary_accuracy: 0.6410\n",
      "Epoch 40/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1298 - binary_accuracy: 0.7464 - val_loss: 1.0497 - val_binary_accuracy: 0.6667\n",
      "Epoch 41/250\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1285 - binary_accuracy: 0.7435 - val_loss: 1.0485 - val_binary_accuracy: 0.6667\n",
      "Epoch 42/250\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1279 - binary_accuracy: 0.7522 - val_loss: 1.0472 - val_binary_accuracy: 0.6667\n",
      "Epoch 43/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1268 - binary_accuracy: 0.7320 - val_loss: 1.0460 - val_binary_accuracy: 0.6667\n",
      "Epoch 44/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.1241 - binary_accuracy: 0.7579 - val_loss: 1.0447 - val_binary_accuracy: 0.6667\n",
      "Epoch 45/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1212 - binary_accuracy: 0.7781 - val_loss: 1.0435 - val_binary_accuracy: 0.6667\n",
      "Epoch 46/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1220 - binary_accuracy: 0.7464 - val_loss: 1.0423 - val_binary_accuracy: 0.6667\n",
      "Epoch 47/250\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1180 - binary_accuracy: 0.7579 - val_loss: 1.0411 - val_binary_accuracy: 0.6667\n",
      "Epoch 48/250\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1155 - binary_accuracy: 0.7723 - val_loss: 1.0399 - val_binary_accuracy: 0.6667\n",
      "Epoch 49/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.1122 - binary_accuracy: 0.7839 - val_loss: 1.0386 - val_binary_accuracy: 0.6667\n",
      "Epoch 50/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.1129 - binary_accuracy: 0.7579 - val_loss: 1.0375 - val_binary_accuracy: 0.6667\n",
      "Epoch 51/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.1100 - binary_accuracy: 0.7867 - val_loss: 1.0363 - val_binary_accuracy: 0.6667\n",
      "Epoch 52/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.1072 - binary_accuracy: 0.7839 - val_loss: 1.0351 - val_binary_accuracy: 0.6667\n",
      "Epoch 53/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.1065 - binary_accuracy: 0.7695 - val_loss: 1.0339 - val_binary_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1030 - binary_accuracy: 0.7896 - val_loss: 1.0327 - val_binary_accuracy: 0.6410\n",
      "Epoch 55/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.1028 - binary_accuracy: 0.7810 - val_loss: 1.0315 - val_binary_accuracy: 0.6410\n",
      "Epoch 56/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0992 - binary_accuracy: 0.7925 - val_loss: 1.0304 - val_binary_accuracy: 0.6410\n",
      "Epoch 57/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0974 - binary_accuracy: 0.7810 - val_loss: 1.0292 - val_binary_accuracy: 0.6410\n",
      "Epoch 58/250\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0981 - binary_accuracy: 0.8012 - val_loss: 1.0280 - val_binary_accuracy: 0.6410\n",
      "Epoch 59/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0939 - binary_accuracy: 0.7954 - val_loss: 1.0269 - val_binary_accuracy: 0.6410\n",
      "Epoch 60/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0908 - binary_accuracy: 0.8271 - val_loss: 1.0257 - val_binary_accuracy: 0.6410\n",
      "Epoch 61/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0900 - binary_accuracy: 0.7867 - val_loss: 1.0246 - val_binary_accuracy: 0.6410\n",
      "Epoch 62/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0857 - binary_accuracy: 0.8242 - val_loss: 1.0235 - val_binary_accuracy: 0.6667\n",
      "Epoch 63/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0865 - binary_accuracy: 0.8156 - val_loss: 1.0224 - val_binary_accuracy: 0.6667\n",
      "Epoch 64/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0849 - binary_accuracy: 0.8040 - val_loss: 1.0213 - val_binary_accuracy: 0.6667\n",
      "Epoch 65/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0839 - binary_accuracy: 0.8069 - val_loss: 1.0201 - val_binary_accuracy: 0.6667\n",
      "Epoch 66/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0826 - binary_accuracy: 0.8127 - val_loss: 1.0190 - val_binary_accuracy: 0.6667\n",
      "Epoch 67/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0790 - binary_accuracy: 0.7983 - val_loss: 1.0179 - val_binary_accuracy: 0.6667\n",
      "Epoch 68/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0784 - binary_accuracy: 0.8040 - val_loss: 1.0168 - val_binary_accuracy: 0.6667\n",
      "Epoch 69/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0760 - binary_accuracy: 0.8242 - val_loss: 1.0157 - val_binary_accuracy: 0.6667\n",
      "Epoch 70/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0729 - binary_accuracy: 0.8329 - val_loss: 1.0146 - val_binary_accuracy: 0.6667\n",
      "Epoch 71/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0721 - binary_accuracy: 0.8271 - val_loss: 1.0135 - val_binary_accuracy: 0.6667\n",
      "Epoch 72/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0694 - binary_accuracy: 0.8242 - val_loss: 1.0124 - val_binary_accuracy: 0.6667\n",
      "Epoch 73/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0673 - binary_accuracy: 0.844 - 0s 100ms/step - loss: 1.0673 - binary_accuracy: 0.8444 - val_loss: 1.0113 - val_binary_accuracy: 0.6667\n",
      "Epoch 74/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0664 - binary_accuracy: 0.8184 - val_loss: 1.0102 - val_binary_accuracy: 0.6667\n",
      "Epoch 75/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0656 - binary_accuracy: 0.8530 - val_loss: 1.0091 - val_binary_accuracy: 0.6667\n",
      "Epoch 76/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0621 - binary_accuracy: 0.8127 - val_loss: 1.0080 - val_binary_accuracy: 0.6667\n",
      "Epoch 77/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0651 - binary_accuracy: 0.8184 - val_loss: 1.0070 - val_binary_accuracy: 0.6667\n",
      "Epoch 78/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.0604 - binary_accuracy: 0.8329 - val_loss: 1.0059 - val_binary_accuracy: 0.6667\n",
      "Epoch 79/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.0571 - binary_accuracy: 0.8415 - val_loss: 1.0049 - val_binary_accuracy: 0.6667\n",
      "Epoch 80/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0559 - binary_accuracy: 0.8386 - val_loss: 1.0038 - val_binary_accuracy: 0.6667\n",
      "Epoch 81/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0544 - binary_accuracy: 0.8386 - val_loss: 1.0028 - val_binary_accuracy: 0.6667\n",
      "Epoch 82/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0521 - binary_accuracy: 0.8415 - val_loss: 1.0017 - val_binary_accuracy: 0.6667\n",
      "Epoch 83/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0494 - binary_accuracy: 0.8386 - val_loss: 1.0007 - val_binary_accuracy: 0.6667\n",
      "Epoch 84/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0503 - binary_accuracy: 0.8588 - val_loss: 0.9997 - val_binary_accuracy: 0.6667\n",
      "Epoch 85/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0464 - binary_accuracy: 0.8559 - val_loss: 0.9987 - val_binary_accuracy: 0.6667\n",
      "Epoch 86/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0449 - binary_accuracy: 0.8617 - val_loss: 0.9977 - val_binary_accuracy: 0.6667\n",
      "Epoch 87/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0429 - binary_accuracy: 0.8242 - val_loss: 0.9966 - val_binary_accuracy: 0.6667\n",
      "Epoch 88/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0420 - binary_accuracy: 0.8300 - val_loss: 0.9956 - val_binary_accuracy: 0.6667\n",
      "Epoch 89/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0423 - binary_accuracy: 0.8357 - val_loss: 0.9946 - val_binary_accuracy: 0.6667\n",
      "Epoch 90/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0363 - binary_accuracy: 0.8530 - val_loss: 0.9936 - val_binary_accuracy: 0.6667\n",
      "Epoch 91/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0355 - binary_accuracy: 0.8444 - val_loss: 0.9926 - val_binary_accuracy: 0.6667\n",
      "Epoch 92/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0349 - binary_accuracy: 0.8559 - val_loss: 0.9916 - val_binary_accuracy: 0.6667\n",
      "Epoch 93/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0332 - binary_accuracy: 0.8444 - val_loss: 0.9906 - val_binary_accuracy: 0.6667\n",
      "Epoch 94/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0295 - binary_accuracy: 0.8790 - val_loss: 0.9896 - val_binary_accuracy: 0.6667\n",
      "Epoch 95/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0305 - binary_accuracy: 0.8473 - val_loss: 0.9886 - val_binary_accuracy: 0.6667\n",
      "Epoch 96/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0282 - binary_accuracy: 0.8329 - val_loss: 0.9876 - val_binary_accuracy: 0.6667\n",
      "Epoch 97/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0263 - binary_accuracy: 0.8559 - val_loss: 0.9866 - val_binary_accuracy: 0.6667\n",
      "Epoch 98/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0228 - binary_accuracy: 0.8761 - val_loss: 0.9856 - val_binary_accuracy: 0.6667\n",
      "Epoch 99/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0208 - binary_accuracy: 0.8847 - val_loss: 0.9846 - val_binary_accuracy: 0.6667\n",
      "Epoch 100/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0204 - binary_accuracy: 0.8559 - val_loss: 0.9836 - val_binary_accuracy: 0.6667\n",
      "Epoch 101/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0194 - binary_accuracy: 0.8646 - val_loss: 0.9827 - val_binary_accuracy: 0.6667\n",
      "Epoch 102/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0181 - binary_accuracy: 0.8703 - val_loss: 0.9817 - val_binary_accuracy: 0.6667\n",
      "Epoch 103/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0155 - binary_accuracy: 0.8530 - val_loss: 0.9807 - val_binary_accuracy: 0.6667\n",
      "Epoch 104/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0148 - binary_accuracy: 0.8646 - val_loss: 0.9797 - val_binary_accuracy: 0.6667\n",
      "Epoch 105/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0110 - binary_accuracy: 0.8674 - val_loss: 0.9787 - val_binary_accuracy: 0.6667\n",
      "Epoch 106/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0099 - binary_accuracy: 0.8588 - val_loss: 0.9777 - val_binary_accuracy: 0.6667\n",
      "Epoch 107/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0085 - binary_accuracy: 0.8588 - val_loss: 0.9768 - val_binary_accuracy: 0.6923\n",
      "Epoch 108/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.0062 - binary_accuracy: 0.8530 - val_loss: 0.9758 - val_binary_accuracy: 0.6923\n",
      "Epoch 109/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0016 - binary_accuracy: 0.8646 - val_loss: 0.9748 - val_binary_accuracy: 0.6923\n",
      "Epoch 110/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.0037 - binary_accuracy: 0.8530 - val_loss: 0.9738 - val_binary_accuracy: 0.6923\n",
      "Epoch 111/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9986 - binary_accuracy: 0.8818 - val_loss: 0.9728 - val_binary_accuracy: 0.6923\n",
      "Epoch 112/250\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9999 - binary_accuracy: 0.8761 - val_loss: 0.9718 - val_binary_accuracy: 0.6923\n",
      "Epoch 113/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.9977 - binary_accuracy: 0.8646 - val_loss: 0.9709 - val_binary_accuracy: 0.6923\n",
      "Epoch 114/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9965 - binary_accuracy: 0.8617 - val_loss: 0.9699 - val_binary_accuracy: 0.7179\n",
      "Epoch 115/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.9960 - binary_accuracy: 0.8674 - val_loss: 0.9689 - val_binary_accuracy: 0.7179\n",
      "Epoch 116/250\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.9899 - binary_accuracy: 0.8761 - val_loss: 0.9680 - val_binary_accuracy: 0.7179\n",
      "Epoch 117/250\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9917 - binary_accuracy: 0.8732 - val_loss: 0.9670 - val_binary_accuracy: 0.7179\n",
      "Epoch 118/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9905 - binary_accuracy: 0.8732 - val_loss: 0.9660 - val_binary_accuracy: 0.7179\n",
      "Epoch 119/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.9855 - binary_accuracy: 0.8790 - val_loss: 0.9651 - val_binary_accuracy: 0.7179\n",
      "Epoch 120/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.9819 - binary_accuracy: 0.8761 - val_loss: 0.9642 - val_binary_accuracy: 0.7179\n",
      "Epoch 121/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9792 - binary_accuracy: 0.8761 - val_loss: 0.9632 - val_binary_accuracy: 0.7179\n",
      "Epoch 122/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9814 - binary_accuracy: 0.8646 - val_loss: 0.9623 - val_binary_accuracy: 0.7179\n",
      "Epoch 123/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9786 - binary_accuracy: 0.8876 - val_loss: 0.9614 - val_binary_accuracy: 0.7179\n",
      "Epoch 124/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.9778 - binary_accuracy: 0.8703 - val_loss: 0.9604 - val_binary_accuracy: 0.7179\n",
      "Epoch 125/250\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.9753 - binary_accuracy: 0.8847 - val_loss: 0.9595 - val_binary_accuracy: 0.7179\n",
      "Epoch 126/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9727 - binary_accuracy: 0.8876 - val_loss: 0.9586 - val_binary_accuracy: 0.7179\n",
      "Epoch 127/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9730 - binary_accuracy: 0.8674 - val_loss: 0.9577 - val_binary_accuracy: 0.7179\n",
      "Epoch 128/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9727 - binary_accuracy: 0.8818 - val_loss: 0.9567 - val_binary_accuracy: 0.7436\n",
      "Epoch 129/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9672 - binary_accuracy: 0.8703 - val_loss: 0.9558 - val_binary_accuracy: 0.7436\n",
      "Epoch 130/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9664 - binary_accuracy: 0.8790 - val_loss: 0.9549 - val_binary_accuracy: 0.7436\n",
      "Epoch 131/250\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9638 - binary_accuracy: 0.8847 - val_loss: 0.9540 - val_binary_accuracy: 0.7436\n",
      "Epoch 132/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9642 - binary_accuracy: 0.8934 - val_loss: 0.9531 - val_binary_accuracy: 0.7436\n",
      "Epoch 133/250\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.9630 - binary_accuracy: 0.8876 - val_loss: 0.9522 - val_binary_accuracy: 0.7436\n",
      "Epoch 134/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.9574 - binary_accuracy: 0.8905 - val_loss: 0.9512 - val_binary_accuracy: 0.7436\n",
      "Epoch 135/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9561 - binary_accuracy: 0.8905 - val_loss: 0.9503 - val_binary_accuracy: 0.7436\n",
      "Epoch 136/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.9571 - binary_accuracy: 0.8761 - val_loss: 0.9494 - val_binary_accuracy: 0.7436\n",
      "Epoch 137/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9559 - binary_accuracy: 0.8876 - val_loss: 0.9485 - val_binary_accuracy: 0.7436\n",
      "Epoch 138/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9524 - binary_accuracy: 0.8588 - val_loss: 0.9476 - val_binary_accuracy: 0.7436\n",
      "Epoch 139/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9488 - binary_accuracy: 0.8703 - val_loss: 0.9466 - val_binary_accuracy: 0.7436\n",
      "Epoch 140/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9473 - binary_accuracy: 0.8847 - val_loss: 0.9457 - val_binary_accuracy: 0.7436\n",
      "Epoch 141/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9473 - binary_accuracy: 0.8818 - val_loss: 0.9448 - val_binary_accuracy: 0.7436\n",
      "Epoch 142/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9447 - binary_accuracy: 0.8963 - val_loss: 0.9439 - val_binary_accuracy: 0.7436\n",
      "Epoch 143/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9418 - binary_accuracy: 0.8876 - val_loss: 0.9430 - val_binary_accuracy: 0.7436\n",
      "Epoch 144/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9419 - binary_accuracy: 0.8732 - val_loss: 0.9421 - val_binary_accuracy: 0.7692\n",
      "Epoch 145/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9375 - binary_accuracy: 0.8818 - val_loss: 0.9412 - val_binary_accuracy: 0.7692\n",
      "Epoch 146/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9389 - binary_accuracy: 0.8847 - val_loss: 0.9403 - val_binary_accuracy: 0.7692\n",
      "Epoch 147/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.9347 - binary_accuracy: 0.8991 - val_loss: 0.9394 - val_binary_accuracy: 0.7949\n",
      "Epoch 148/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9341 - binary_accuracy: 0.8876 - val_loss: 0.9384 - val_binary_accuracy: 0.7949\n",
      "Epoch 149/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9299 - binary_accuracy: 0.8905 - val_loss: 0.9375 - val_binary_accuracy: 0.7949\n",
      "Epoch 150/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9305 - binary_accuracy: 0.8761 - val_loss: 0.9366 - val_binary_accuracy: 0.7949\n",
      "Epoch 151/250\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.9279 - binary_accuracy: 0.8991 - val_loss: 0.9357 - val_binary_accuracy: 0.7949\n",
      "Epoch 152/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9283 - binary_accuracy: 0.8847 - val_loss: 0.9348 - val_binary_accuracy: 0.7949\n",
      "Epoch 153/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9235 - binary_accuracy: 0.8905 - val_loss: 0.9339 - val_binary_accuracy: 0.7949\n",
      "Epoch 154/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.9244 - binary_accuracy: 0.8876 - val_loss: 0.9330 - val_binary_accuracy: 0.7949\n",
      "Epoch 155/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9224 - binary_accuracy: 0.8847 - val_loss: 0.9321 - val_binary_accuracy: 0.7949\n",
      "Epoch 156/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9178 - binary_accuracy: 0.9020 - val_loss: 0.9313 - val_binary_accuracy: 0.7949\n",
      "Epoch 157/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9171 - binary_accuracy: 0.9020 - val_loss: 0.9304 - val_binary_accuracy: 0.7949\n",
      "Epoch 158/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9147 - binary_accuracy: 0.8876 - val_loss: 0.9295 - val_binary_accuracy: 0.7949\n",
      "Epoch 159/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.9094 - binary_accuracy: 0.8876 - val_loss: 0.9286 - val_binary_accuracy: 0.7949\n",
      "Epoch 160/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9091 - binary_accuracy: 0.8991 - val_loss: 0.9278 - val_binary_accuracy: 0.7949\n",
      "Epoch 161/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.9073 - binary_accuracy: 0.8905 - val_loss: 0.9269 - val_binary_accuracy: 0.7949\n",
      "Epoch 162/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.9029 - binary_accuracy: 0.9193 - val_loss: 0.9260 - val_binary_accuracy: 0.7949\n",
      "Epoch 163/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.9043 - binary_accuracy: 0.8905 - val_loss: 0.9251 - val_binary_accuracy: 0.7949\n",
      "Epoch 164/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.9038 - binary_accuracy: 0.8847 - val_loss: 0.9242 - val_binary_accuracy: 0.7949\n",
      "Epoch 165/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9008 - binary_accuracy: 0.9078 - val_loss: 0.9234 - val_binary_accuracy: 0.7949\n",
      "Epoch 166/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8996 - binary_accuracy: 0.8934 - val_loss: 0.9225 - val_binary_accuracy: 0.7949\n",
      "Epoch 167/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8969 - binary_accuracy: 0.9078 - val_loss: 0.9216 - val_binary_accuracy: 0.7949\n",
      "Epoch 168/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8957 - binary_accuracy: 0.8934 - val_loss: 0.9208 - val_binary_accuracy: 0.7949\n",
      "Epoch 169/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8985 - binary_accuracy: 0.8876 - val_loss: 0.9199 - val_binary_accuracy: 0.7949\n",
      "Epoch 170/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8907 - binary_accuracy: 0.9107 - val_loss: 0.9191 - val_binary_accuracy: 0.7949\n",
      "Epoch 171/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8906 - binary_accuracy: 0.8963 - val_loss: 0.9182 - val_binary_accuracy: 0.7949\n",
      "Epoch 172/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8879 - binary_accuracy: 0.8991 - val_loss: 0.9174 - val_binary_accuracy: 0.7949\n",
      "Epoch 173/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8880 - binary_accuracy: 0.9049 - val_loss: 0.9166 - val_binary_accuracy: 0.7949\n",
      "Epoch 174/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8829 - binary_accuracy: 0.8963 - val_loss: 0.9157 - val_binary_accuracy: 0.7949\n",
      "Epoch 175/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8818 - binary_accuracy: 0.9020 - val_loss: 0.9149 - val_binary_accuracy: 0.7949\n",
      "Epoch 176/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8817 - binary_accuracy: 0.8991 - val_loss: 0.9141 - val_binary_accuracy: 0.7949\n",
      "Epoch 177/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8761 - binary_accuracy: 0.8905 - val_loss: 0.9133 - val_binary_accuracy: 0.7949\n",
      "Epoch 178/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.8795 - binary_accuracy: 0.9049 - val_loss: 0.9125 - val_binary_accuracy: 0.7949\n",
      "Epoch 179/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8782 - binary_accuracy: 0.8991 - val_loss: 0.9117 - val_binary_accuracy: 0.7949\n",
      "Epoch 180/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8772 - binary_accuracy: 0.8991 - val_loss: 0.9109 - val_binary_accuracy: 0.7949\n",
      "Epoch 181/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8741 - binary_accuracy: 0.9078 - val_loss: 0.9101 - val_binary_accuracy: 0.7949\n",
      "Epoch 182/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8723 - binary_accuracy: 0.9020 - val_loss: 0.9093 - val_binary_accuracy: 0.7949\n",
      "Epoch 183/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8693 - binary_accuracy: 0.8934 - val_loss: 0.9086 - val_binary_accuracy: 0.7949\n",
      "Epoch 184/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8670 - binary_accuracy: 0.8876 - val_loss: 0.9078 - val_binary_accuracy: 0.7949\n",
      "Epoch 185/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8634 - binary_accuracy: 0.9020 - val_loss: 0.9071 - val_binary_accuracy: 0.7949\n",
      "Epoch 186/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8613 - binary_accuracy: 0.9020 - val_loss: 0.9063 - val_binary_accuracy: 0.7949\n",
      "Epoch 187/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8612 - binary_accuracy: 0.9049 - val_loss: 0.9056 - val_binary_accuracy: 0.7949\n",
      "Epoch 188/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8578 - binary_accuracy: 0.9078 - val_loss: 0.9048 - val_binary_accuracy: 0.7949\n",
      "Epoch 189/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8573 - binary_accuracy: 0.9078 - val_loss: 0.9041 - val_binary_accuracy: 0.7949\n",
      "Epoch 190/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8560 - binary_accuracy: 0.8991 - val_loss: 0.9033 - val_binary_accuracy: 0.7949\n",
      "Epoch 191/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8564 - binary_accuracy: 0.9078 - val_loss: 0.9026 - val_binary_accuracy: 0.7949\n",
      "Epoch 192/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8542 - binary_accuracy: 0.9078 - val_loss: 0.9018 - val_binary_accuracy: 0.7949\n",
      "Epoch 193/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8498 - binary_accuracy: 0.9078 - val_loss: 0.9011 - val_binary_accuracy: 0.7949\n",
      "Epoch 194/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8496 - binary_accuracy: 0.9193 - val_loss: 0.9003 - val_binary_accuracy: 0.7949\n",
      "Epoch 195/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8448 - binary_accuracy: 0.9193 - val_loss: 0.8996 - val_binary_accuracy: 0.7949\n",
      "Epoch 196/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8436 - binary_accuracy: 0.9135 - val_loss: 0.8989 - val_binary_accuracy: 0.7949\n",
      "Epoch 197/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8466 - binary_accuracy: 0.8991 - val_loss: 0.8982 - val_binary_accuracy: 0.7949\n",
      "Epoch 198/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8393 - binary_accuracy: 0.9049 - val_loss: 0.8975 - val_binary_accuracy: 0.7949\n",
      "Epoch 199/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8345 - binary_accuracy: 0.9222 - val_loss: 0.8968 - val_binary_accuracy: 0.7949\n",
      "Epoch 200/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8388 - binary_accuracy: 0.9135 - val_loss: 0.8961 - val_binary_accuracy: 0.7949\n",
      "Epoch 201/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8375 - binary_accuracy: 0.9193 - val_loss: 0.8954 - val_binary_accuracy: 0.7949\n",
      "Epoch 202/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8356 - binary_accuracy: 0.9164 - val_loss: 0.8948 - val_binary_accuracy: 0.7949\n",
      "Epoch 203/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8296 - binary_accuracy: 0.9222 - val_loss: 0.8941 - val_binary_accuracy: 0.7949\n",
      "Epoch 204/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8282 - binary_accuracy: 0.9107 - val_loss: 0.8935 - val_binary_accuracy: 0.7949\n",
      "Epoch 205/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8295 - binary_accuracy: 0.9135 - val_loss: 0.8929 - val_binary_accuracy: 0.7949\n",
      "Epoch 206/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8319 - binary_accuracy: 0.9164 - val_loss: 0.8922 - val_binary_accuracy: 0.7949\n",
      "Epoch 207/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8249 - binary_accuracy: 0.9078 - val_loss: 0.8915 - val_binary_accuracy: 0.7949\n",
      "Epoch 208/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8230 - binary_accuracy: 0.9193 - val_loss: 0.8909 - val_binary_accuracy: 0.7949\n",
      "Epoch 209/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8229 - binary_accuracy: 0.9107 - val_loss: 0.8902 - val_binary_accuracy: 0.7949\n",
      "Epoch 210/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8179 - binary_accuracy: 0.9193 - val_loss: 0.8896 - val_binary_accuracy: 0.7949\n",
      "Epoch 211/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8204 - binary_accuracy: 0.9135 - val_loss: 0.8889 - val_binary_accuracy: 0.7949\n",
      "Epoch 212/250\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8184 - binary_accuracy: 0.9193 - val_loss: 0.8883 - val_binary_accuracy: 0.7949\n",
      "Epoch 213/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8171 - binary_accuracy: 0.9164 - val_loss: 0.8876 - val_binary_accuracy: 0.7949\n",
      "Epoch 214/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8177 - binary_accuracy: 0.925 - 0s 98ms/step - loss: 0.8177 - binary_accuracy: 0.9251 - val_loss: 0.8869 - val_binary_accuracy: 0.7949\n",
      "Epoch 215/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8125 - binary_accuracy: 0.9135 - val_loss: 0.8862 - val_binary_accuracy: 0.7949\n",
      "Epoch 216/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8081 - binary_accuracy: 0.9308 - val_loss: 0.8855 - val_binary_accuracy: 0.7949\n",
      "Epoch 217/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7997 - binary_accuracy: 0.9337 - val_loss: 0.8848 - val_binary_accuracy: 0.7949\n",
      "Epoch 218/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8059 - binary_accuracy: 0.9337 - val_loss: 0.8842 - val_binary_accuracy: 0.7949\n",
      "Epoch 219/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8081 - binary_accuracy: 0.9251 - val_loss: 0.8835 - val_binary_accuracy: 0.7949\n",
      "Epoch 220/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8026 - binary_accuracy: 0.9164 - val_loss: 0.8828 - val_binary_accuracy: 0.7692\n",
      "Epoch 221/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.8013 - binary_accuracy: 0.9222 - val_loss: 0.8821 - val_binary_accuracy: 0.7692\n",
      "Epoch 222/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8022 - binary_accuracy: 0.9193 - val_loss: 0.8814 - val_binary_accuracy: 0.7692\n",
      "Epoch 223/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7991 - binary_accuracy: 0.9308 - val_loss: 0.8807 - val_binary_accuracy: 0.7692\n",
      "Epoch 224/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7958 - binary_accuracy: 0.9280 - val_loss: 0.8801 - val_binary_accuracy: 0.7692\n",
      "Epoch 225/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7920 - binary_accuracy: 0.9366 - val_loss: 0.8794 - val_binary_accuracy: 0.7692\n",
      "Epoch 226/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7904 - binary_accuracy: 0.9308 - val_loss: 0.8788 - val_binary_accuracy: 0.7692\n",
      "Epoch 227/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7917 - binary_accuracy: 0.9280 - val_loss: 0.8781 - val_binary_accuracy: 0.7692\n",
      "Epoch 228/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7885 - binary_accuracy: 0.9337 - val_loss: 0.8775 - val_binary_accuracy: 0.7692\n",
      "Epoch 229/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7876 - binary_accuracy: 0.9337 - val_loss: 0.8768 - val_binary_accuracy: 0.7692\n",
      "Epoch 230/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7844 - binary_accuracy: 0.9366 - val_loss: 0.8762 - val_binary_accuracy: 0.7692\n",
      "Epoch 231/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7803 - binary_accuracy: 0.9308 - val_loss: 0.8756 - val_binary_accuracy: 0.7692\n",
      "Epoch 232/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7795 - binary_accuracy: 0.9308 - val_loss: 0.8750 - val_binary_accuracy: 0.7692\n",
      "Epoch 233/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7794 - binary_accuracy: 0.9251 - val_loss: 0.8744 - val_binary_accuracy: 0.7692\n",
      "Epoch 234/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7802 - binary_accuracy: 0.9424 - val_loss: 0.8738 - val_binary_accuracy: 0.7692\n",
      "Epoch 235/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7747 - binary_accuracy: 0.9395 - val_loss: 0.8733 - val_binary_accuracy: 0.7692\n",
      "Epoch 236/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7728 - binary_accuracy: 0.9366 - val_loss: 0.8727 - val_binary_accuracy: 0.7692\n",
      "Epoch 237/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7741 - binary_accuracy: 0.9424 - val_loss: 0.8722 - val_binary_accuracy: 0.7692\n",
      "Epoch 238/250\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7711 - binary_accuracy: 0.9481 - val_loss: 0.8716 - val_binary_accuracy: 0.7692\n",
      "Epoch 239/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7709 - binary_accuracy: 0.9395 - val_loss: 0.8712 - val_binary_accuracy: 0.7692\n",
      "Epoch 240/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7674 - binary_accuracy: 0.9280 - val_loss: 0.8707 - val_binary_accuracy: 0.7692\n",
      "Epoch 241/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7642 - binary_accuracy: 0.9337 - val_loss: 0.8702 - val_binary_accuracy: 0.7692\n",
      "Epoch 242/250\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7671 - binary_accuracy: 0.9395 - val_loss: 0.8697 - val_binary_accuracy: 0.7692\n",
      "Epoch 243/250\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7616 - binary_accuracy: 0.9395 - val_loss: 0.8692 - val_binary_accuracy: 0.7692\n",
      "Epoch 244/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7616 - binary_accuracy: 0.9424 - val_loss: 0.8688 - val_binary_accuracy: 0.7692\n",
      "Epoch 245/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7590 - binary_accuracy: 0.9337 - val_loss: 0.8683 - val_binary_accuracy: 0.7692\n",
      "Epoch 246/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7571 - binary_accuracy: 0.9395 - val_loss: 0.8679 - val_binary_accuracy: 0.7692\n",
      "Epoch 247/250\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7592 - binary_accuracy: 0.9337 - val_loss: 0.8674 - val_binary_accuracy: 0.7692\n",
      "Epoch 248/250\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7562 - binary_accuracy: 0.9452 - val_loss: 0.8670 - val_binary_accuracy: 0.7436\n",
      "Epoch 249/250\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7526 - binary_accuracy: 0.9337 - val_loss: 0.8665 - val_binary_accuracy: 0.7436\n",
      "Epoch 250/250\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7542 - binary_accuracy: 0.9366 - val_loss: 0.8661 - val_binary_accuracy: 0.7436\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt=k.optimizers.Adam(lr=1e-5) \n",
    "metric= [k.metrics.BinaryAccuracy()] \n",
    "model.compile(loss='binary_crossentropy',  optimizer=opt  , metrics=metric)\n",
    "history=model.fit(Xtr, ytr, validation_split=0.1, epochs=250, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e04be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7392 - binary_accuracy: 0.9249\n",
      "Accuracy: 92.49\n"
     ]
    }
   ],
   "source": [
    "_,accuracy = model.evaluate(Xtr,ytr)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "873acfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8676 - binary_accuracy: 0.7711\n",
      "Accuracy: 77.11\n"
     ]
    }
   ],
   "source": [
    "_,accuracy = model.evaluate(Xts,yts)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ccc137",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "#plt.savefig(\"train_loss2.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"binary_accuracy\"])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.savefig(\"train_accuracy2.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584097eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557872f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f630dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'model2.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772a744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
